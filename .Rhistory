n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ High5, data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ !!rlang::sym(High5), data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
data_channel_train[High5]
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ data_channel_train[High5], data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
High5
str(High5)
list(High5)
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ list(High5), data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
help("train")
help("train")
High5
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ LDA_03* n.Images* n.Content *Avg.Avg.Key *n.Videos , data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## plot to visualize parameters
plot(gbm_tree_cv)
gbm_tree_cv
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ . , data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## plot to visualize parameters
plot(gbm_tree_cv)
gbm_tree_cv
## linear regression model using all predictors
set.seed(13)
linear_model_1 <- train( shares ~ .,
data = data_channel_train,
method = "lm",
preProcess = c("center", "scale"),
trControl = trainControl(method = "cv",
number = 5))
## prediction of test with model
linear_model_1_pred <- predict(linear_model_1, newdata = dplyr::select(data_channel_test, -shares))
## storing error of model on test set
linear_1_RMSE<- postResample(linear_model_1_pred, obs = data_channel_test$shares)
## Delete ## i think this looks good! smart things to cut out, i will try to improve mine. ##
#Removed rate.Nonstop because it was only 1 and removed the days of the week.
linear_model_2 <- train( shares ~. - Rate.Nonstop - Mon
- Tues - Wed - Thurs - Fri - Sat
- Sun - Weekend,
data = lifestyle_train,
method = "lm",
preProcess = c("center",
"scale"),
trControl = trainControl(
method= "cv",
number = 5))
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
lifestyle <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
lifestyle <- lifestyle %>%
filter(Lifestyle == 1)
#Drop the data_channel_is column
lifestyle <- lifestyle[ , -c(12)]
lifestyle <- lifestyle[ , c(53, 1:52)]
#Split the data into training and test
set.seed(5432)
# Split the data into a training and test set (70/30 split)
# indices
train <- sample(1:nrow(lifestyle), size = nrow(lifestyle)*.70)
test <- setdiff(1:nrow(lifestyle), train)
# trainiing and testing subsets
lifestyle_train <- lifestyle[train, ]
lifestyle_test <- lifestyle[test, ]
## Delete ## i think this looks good! smart things to cut out, i will try to improve mine. ##
#Removed rate.Nonstop because it was only 1 and removed the days of the week.
linear_model_2 <- train( shares ~. - Rate.Nonstop - Mon
- Tues - Wed - Thurs - Fri - Sat
- Sun - Weekend,
data = lifestyle_train,
method = "lm",
preProcess = c("center",
"scale"),
trControl = trainControl(
method= "cv",
number = 5))
## prediction of test with model
linear_model_2_pred <- predict(linear_model_2, newdata = dplyr::select(lifestyle_test, -shares))
## storing error of model on test set
linear_2_RMSE<- postResample(linear_model_2_pred, obs = lifestyle_test$shares)
set.seed(10210526)
rfFit <- train(shares ~ .,
data = lifestyle_train,
method = "rf",
trControl = trainControl(method = "cv",
number = 5),
preProcess = c("center", "scale"),
tuneGrid =
data.frame(mtry = ncol(lifestyle_train)/3))
rfFit_pred <- predict(rfFit, newdata = lifestyle_test)
rfRMSE<- postResample(rfFit_pred, obs =
lifestyle_test$shares)
## Delete## i think it looks good! i will need to rewatch the lecture and try to dig in some more cause im really lost on these ensamble tree based models. i think you chose some good ones to remove.  the only thing is in the project it says "Both models should be chosen using cross-validation" for random forest and boosted tree, so i think the random forest does need cv unless im missing something. Im still trying to figure out what is wrong with my cross validation and a way to take the tuning parameters based on each data_channel_is during the automation process. I think we are close though!
## Delete## I rewatched the lecture for model fitting using the caret package. I made the appropriate modifications. I tried to use the tuneGrid but the code was trying to run for over 5 minutes and it never went through, so I used the suggested mtry for regression from the random forest lecture.
## delete## So i went through the random forrest stuff again while doing the hw that was due today and my random forrest also took forever to run witht the tune grid. i think it just depends on the size of the expand.grid that you give it. we should keep that in mind for when we are doing the final render of the project because it may take forever to render all 6 lol
## creates boosted tree model with tuning parameters n.trees, shrinkage, interaction.depth from CV
## do i need this??
boosted_tree_model <- gbm(shares ~ . , data = data_channel_train,
distribution = "gaussian",
n.trees = 16 ,
shrinkage = 0.1 ,
interaction.depth = 7 )
## test set prediction
boosted_tree_model_pred <- predict(boosted_tree_model, newdata = dplyr::select(data_channel_test, -shares), n.trees = 7)
## stores results
boosted_tree_RMSE <- postResample(boosted_tree_model_pred, obs = data_channel_test$shares)
## creates a data frame of the four models RMSE on the
models_RMSE <- data.frame(linear_1_RMSE=linear_1_RMSE[1],
linear_2_RMSE=linear_2_RMSE[1],
rfRMSE=rfRMSE[1],
boosted_tree_RMSE =
boosted_tree_RMSE[1] )
## gets the name of the column with the smallest rmse
smallest_RMSE<-colnames(models_RMSE)[apply(models_RMSE,1,which.min)]
## declares the model with smallest RSME the winner
paste0(" For ",
params$DataChannel, " ",
smallest_RMSE, " is the winner")
models_RMSE
boosted_tree_model
gbm_tree_cv
help("gbm")
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(10, 20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ . , data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## plot to visualize parameters
plot(gbm_tree_cv)
gbm_tree_cv
rfFit
models_RMSE
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(10,20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ . , data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## plot to visualize parameters
plot(gbm_tree_cv)
## test set prediction
boosted_tree_model_pred <- predict(gbm_tree_cv, newdata = dplyr::select(data_channel_test, -shares), n.trees = 7)
## stores results
boosted_tree_RMSE <- postResample(gbm_tree_cv, obs = data_channel_test$shares)
## stores results
boosted_tree_RMSE <- postResample(boosted_tree_model_pred, obs = data_channel_test$shares)
boosted_tree_RMSE
gbm_tree_cv
models_RMSE
boosted_tree_RMSE
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(10,20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
High5 <- shares_correlations[48:52] %>% names() %>% noquote()
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ . , data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## plot to visualize parameters
plot(gbm_tree_cv)
## test set prediction
boosted_tree_model_pred <- predict(gbm_tree_cv, newdata = dplyr::select(data_channel_test, -shares), n.trees = 7)
## stores results
boosted_tree_RMSE <- postResample(boosted_tree_model_pred, obs = data_channel_test$shares)
## creates a data frame of the four models RMSE on the
models_RMSE <- data.frame(linear_1_RMSE=linear_1_RMSE[1],
linear_2_RMSE=linear_2_RMSE[1],
rfRMSE=rfRMSE[1],
boosted_tree_RMSE =
boosted_tree_RMSE[1] )
## gets the name of the column with the smallest rmse
smallest_RMSE<-colnames(models_RMSE)[apply(models_RMSE,1,which.min)]
## declares the model with smallest RSME the winner
paste0(" For ",
params$DataChannel, " ",
smallest_RMSE, " is the winner")
library(tidyverse)
library(knitr)
library(GGally)
library(corrplot)
library(qwraps2)
library(vtable)
library(psych)
library(ggplot2)
library(cowplot)
library(caret)
library(gbm)
library(randomForest)
library(tree)
library(class)
library(bst)
library(reshape)
library(reshape2)
library(corrr)
library(ggcorrplot)
library(FactoMineR)
library(factoextra)
## DELETE## changed this so it would knit on my machine feel free to change it back if I forget to
#setwd("C:/Documents/Github/ST_558_Project_2")
setwd("C:/Users/Demetri/Documents/NCSU_masters/ST558/Repos/GitHub/ST_558_Project_2")
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
#All trained data sets are in another .Rmd file called Create_dataframes_use_later. These can be copy and pasted when they are necessary
## I'm not 100% sure but I think we are supposed to run this same process with the different params set up. so its like just one doc that we knit with the six different params and it goes through and does everything without us needing to copy and paste
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
## Drop the data_channel_is columns
data_channel <- data_channel[ , -c(12:17)]
## reorder to put shares first
data_channel <- data_channel[ , c(53, 1:52)]
set.seed(5432)
# Split the data into a training and test set (70/30 split)
# indices
train <- sample(1:nrow(data_channel), size = nrow(data_channel)*.70)
test <- setdiff(1:nrow(data_channel), train)
# training and testing subsets
data_channel_train <- data_channel[train, ]
data_channel_test <- data_channel[test, ]
## makes correlation of every variable with shares
shares_correlations <- cor(data_channel_train)[1,] %>% sort()
shares_correlations
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point() + labs + ggtitle(" Highest correlated variable with shares")
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point() +geom_smooth( method = lm)  + ggtitle(" Highest correlated variable with shares")
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point(aes(color=red)) +geom_smooth( method = lm)  + ggtitle(" Highest correlated variable with shares")
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point(color=red) +geom_smooth( method = lm)  + ggtitle(" Highest correlated variable with shares")
names(data_channel_train)
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point(aes(color=Weekend)) +geom_smooth( method = lm)  + ggtitle(" Highest correlated variable with shares")
data_channel_train$Weekend
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point(aes(color=as.factor(Weekend))) +geom_smooth( method = lm)  + ggtitle(" Highest correlated variable with shares")
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point(aes(color=as.factor(Weekend))) +geom_smooth(method = lm) + ggtitle(" Highest correlated variable with shares") + labs(x="Highest correlated variable")
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point(aes(color=as.factor(Weekend))) +geom_smooth(method = lm) + ggtitle(" Highest correlated variable with shares") + labs(x="Highest correlated variable", color="Weekend")
help("mutate")
#at least 2 factors
#shares exceeded median and wether program was on the weekend
#wether or not it was the weekend
# cut()
shareshigh <- data_channel_train %>% select(shares) %>% mutate (shareshigh == (shares> mean(shares)))
#at least 2 factors
#shares exceeded median and wether program was on the weekend
#wether or not it was the weekend
# cut()
shareshigh <- data_channel_train %>% select(shares) %>% mutate (shareshigh = (shares> mean(shares)))
shareshigh$shareshigh
#at least 2 factors
#shares exceeded median and wether program was on the weekend
#wether or not it was the weekend
# cut()
mean(data_channel_train$shares)
#at least 2 factors
#shares exceeded median and wether program was on the weekend
#wether or not it was the weekend
# cut()
mean(data_channel_train$shares)
sd(data_channel_train$shares )
shareshigh <- data_channel_train %>% select(shares) %>% mutate (shareshigh = (shares> mean(shares)))
#is weekend shares high %>% table prop table relative freq
# prop.table(margin= "isweekend")
help(sd)
names(data_channel_train)
data_channel_train$Weekend
data_channel_train$shareshigh
shareshigh$shareshigh
help(prop.table)
help(table)
## creates a contingency table of shareshigh and whether it is the weekend
table(shareshigh$shareshigh, data_channel_train$Weekend)
## creates a contingency table of shareshigh and whether it is the weekend
prop.table(shareshigh$shareshigh, data_channel_train$Weekend)
names(data_channel_train)
## creates  a contingency table of shareshigh and whether it is the weekend
table(shareshigh$shareshigh, data_channel_train$Mon)
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram()
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram(color=Weekend)
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram(aes(fill=Weekend)
a <- ggplot(data_channel_train, aes(x=shares))
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram(aes(fill=Weekend))
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram(color=red)
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram(color==red)
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram(color= "red")
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram(color= "red", fill="blue")
a <- ggplot(data_channel_train, aes(x=shares))
a+geom_histogram(color= "red", fill="blue")+ ggtitle("Shares histogram")
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
## creats scatter plot looking at shares vs highest correlated variable
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point(aes(color=as.factor(Weekend))) +geom_smooth(method = lm) + ggtitle(" Highest correlated variable with shares") + labs(x="Highest correlated variable", color="Weekend")
data_channel_train$n.Title
b<- ggplot(data_channel_train, aes(x=n.Title, y=shares))
b+ geom_col()
b<- ggplot(data_channel_train, aes(x=n.Title, y=shares))
b+ geom_col(color="red")
b<- ggplot(data_channel_train, aes(x=n.Title, y=shares))
b+ geom_col(color="blue")
## creates plotting object of shares
a <- ggplot(data_channel_train, aes(x=shares))
## histogram of shares
a+geom_histogram(color= "red", fill="blue")+ ggtitle("Shares histogram")
b<- ggplot(data_channel_train, aes(x=n.Title, y=shares))
b+ geom_col(color="blue")
b<- ggplot(data_channel_train, aes(x=n.Title, y=shares))
b+ geom_col(fill="blue")
## creates plotting object with number of words in title and shares
b<- ggplot(data_channel_train, aes(x=n.Title, y=shares))
## creates a bar chart with number of words in title and shares
b+ geom_col(fill="blue")+ ggtitle("# of words in title vs shares")
## creates plotting object with number of words in title and shares
b<- ggplot(data_channel_train, aes(x=n.Title, y=shares))
## creates a bar chart with number of words in title and shares
b+ geom_col(fill="blue")+ ggtitle("Number of words in title vs shares") + labs(x="Number of words in title")
