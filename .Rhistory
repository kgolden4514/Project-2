reports[[1]]
## creates a list of all 6 desired params from online
data_channel <- c("Lifestyle", "Entertainment", "Business", "Social.Media", "Tech", "World")
#put into a data frame
reports <- tibble(output_file, data_channel)
reports
reports
reports[[1]]
reports[[2]]
library(rmarkdown)
help("render")
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_file = x[[1]], params = x[[2]]
)
}
)
#create a list for each team with just the team name parameter
params = lapply(data_channel, FUN = function(x){list(data_channel)})
params
data_channel
#create a list for each team with just the team name parameter
params = lapply(data_channel, FUN = function(x){list(data_channel_is = x)})
params
#put into a data frame
reports <- tibble(output_file, data_channel)
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_file = x[[1]], params = x[[2]]
)
}
)
reports
#put into a data frame
reports <- tibble(output_file, params)
reports
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_file = x[[1]], params = x[[2]]
)
}
)
help("render")
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html" output_file = x[[1]], params = x[[2]]
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html", output_file = x[[1]], params = x[[2]]
)
}
)
help("render")
rmarkdown::render(input="./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html", output_file = x[[1]], params = x[[2]]
)
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render(input="./_Rmd/Automation_test.Rmd", output_file = x[[1]], params = x[[2]]
)
}
)
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_file = x[[1]], params = x[[2]]
)
}
)
## creates a list of all 6 desired params from online
data_channel <- c("Lifestyle", "Entertainment", "Business", "Social.Media", "Tech", "World")
output_file <- paste0(data_channel, ".html")
#create a list for each team with just the team name parameter
params = lapply(data_channel, FUN = function(x){list(data_channel_is = x)})
#put into a data frame
reports <- tibble(output_file, params)
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_file = x[[1]], params = x[[2]]
)
}
)
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_file = x[[1]], params = x[[2]]
)
}
)
reports
reports[[2]]
#create a list for each team with just the team name parameter
params = lapply(data_channel, FUN = function(x){list(DataChannel = x)})
#put into a data frame
reports <- tibble(output_file, params)
reports[[2]]
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_file = x[[1]], params = x[[2]]
)
}
)
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html" output_file = x[[1]], params = x[[2]]
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html", output_file = x[[1]], params = x[[2]]
)
}
)
params$DataChannel
params$DataChannel
params$DataChannel
params$DataChannel
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
params$DataChannel <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
params$DataChannel <-  params$DataChannel %>%
filter(params$DataChannel == 1)
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
params$DataChannel <- online[ , -c(13:17)]
params$DataChannel
params$DataChannel
params$DataChannel
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
data_channel <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
data_channel <-  data_channel %>%
filter(params$DataChannel == 1)
#Drop the data_channel_is column
data_channel <- data_channel[ , -c(12)]
data_channel <- data_channel[ , c(53, 1:52)]
data_channel
## renders single github doc with parameters lifestyle
#rmarkdown::render("/GitHub/ST_558_Project_2/_Rmd/Automation_test.Rmd", output_file = "Lifestyle.md",
#params = list(data_channel_is = "Lifestyle"))
## renders all 6 documents
## creates a list of all 6 desired params from online
data_channel <- c("Lifestyle", "Entertainment", "Business", "Social.Media", "Tech", "World")
output_file <- paste0(data_channel, ".html")
#create a list for each team with just the team name parameter
params = lapply(data_channel, FUN = function(x){list(DataChannel = x)})
#put into a data frame
reports <- tibble(output_file, params)
## renders with params to all
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html", output_file = x[[1]], params = x[[2]]
)
}
)
## creates a list of all 6 desired params from online
data_channel_is <- c("Lifestyle", "Entertainment", "Business", "Social.Media", "Tech", "World")
output_file <- paste0(data_channel_is, ".html")
#create a list for each team with just the team name parameter
params = lapply(data_channel_is, FUN = function(x){list(DataChannel = x)})
#put into a data frame
reports <- tibble(output_file, params)
params$DataChannel
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
data_channel <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
data_channel <-  data_channel %>%
filter(params$DataChannel == 1)
#Drop the data_channel_is column
data_channel <- data_channel[ , -c(12)]
data_channel <- data_channel[ , c(53, 1:52)]
data_channel
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
data_channel <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
data_channel <-  data_channel %>%
filter(params$DataChannel == 1)
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
#Filter out the zeros from the remaining data_channel_is column
data_channel <-  data_channel %>%
filter(params$DataChannel == 1)
names(data_channel)
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
names(online)
data_channel <-  data_channel %>%
filter(params$DataChannel == 1)
data_channel %>% names()
data_channel <-  online %>%
filter(params$DataChannel == 1)
data_channel %>% names()
data_channel$Lifestyle
data_channel$Buisness
data_channel$Tech
online
online$Lifestyle
# i think if we do this
data_channel <-  online %>% as_tibble() %>% filter(params$DataChannel == 1)
data_channel
data_channel$Rate.Unique.Nonstop
params$DataChannel
online$Rate.Unique
help("filter")
data_channel <-  online %>% as_tibble() %>% filter("Lifestyle" == 1)
data_channel
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
lifestyle <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
lifestyle <- lifestyle %>%
filter(Lifestyle == 1)
#Drop the data_channel_is column
lifestyle <- lifestyle[ , -c(12)]
lifestyle <- lifestyle[ , c(53, 1:52)]
lifestyle
lifestyle %>% as_tibble()
data_channel <-  online %>% filter("Lifestyle" == 1)
data_channel
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
data_channel <- online[ , -c(13:17)]
data_channel
data_channel <-  online %>% filter("Lifestyle" == 1)
data_channel
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
lifestyle <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
lifestyle <- lifestyle %>%
filter(Lifestyle == 1)
#Drop the data_channel_is column
lifestyle <- lifestyle[ , -c(12)]
lifestyle <- lifestyle[ , c(53, 1:52)]
lifestyle
lifestyle <- online %>%
filter(Lifestyle == 1)
lifestyle
params$DataChannel
help(noquote)
data_channel <-  online %>% filter(Lifestyle == 1)
data_channel
data_channel$Lifestyle
# i think if we do this
data_channel <-  online %>% filter(noquote(params$DataChannel) == 1)
data_channel$Lifestyle
# i think if we do this
filter_param <- noquote(params$DataChannel)
filter_param
data_channel <-  online %>% filter( filter_param == 1)
data_channel
install.packages(rlang)
data_channel <-  online %>% filter( !!rlang::sym(filter_param) == 1)
data_channel
data_channel$Lifestyle
online$Lifestyle
## filters rows based on the parameter
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
data_channel
data_channel$Lifestyle
## filters rows based on the parameter
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
data_channel$Lifestyle
params$DataChannel
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
online$Tech
online$Lifestyle
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
data_channel$Lifestyle
data_channel$Tech
## renders single github doc with parameters lifestyle
#rmarkdown::render("/GitHub/ST_558_Project_2/_Rmd/Automation_test.Rmd", output_file = "Lifestyle.md",
#params = list(data_channel_is = "Lifestyle"))
## renders all 6 documents
## creates a list of all 6 desired params from online
data_channel_is <- c("Lifestyle", "Entertainment", "Business", "Social.Media", "Tech", "World")
output_file <- paste0(data_channel_is, ".html")
#create a list for each team with just the team name parameter
params = lapply(data_channel_is, FUN = function(x){list(DataChannel = x)})
#put into a data frame
reports <- tibble(output_file, params)
## renders with params to all
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html", output_file = x[[1]], params = x[[2]]
)
}
)
data_channel$Lifestyle
## testing that it works properly should see all 0s for every data channel other than the parameter
data_channel$Lifestyle
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
## renders single github doc with parameters lifestyle
#rmarkdown::render("/GitHub/ST_558_Project_2/_Rmd/Automation_test.Rmd", output_file = "Lifestyle.md",
#params = list(data_channel_is = "Lifestyle"))
## renders all 6 documents
## creates a list of all 6 desired params from online
data_channel_is <- c("Lifestyle", "Entertainment", "Business", "Social.Media", "Tech", "World")
output_file <- paste0(data_channel_is, ".html")
#create a list for each team with just the team name parameter
params = lapply(data_channel_is, FUN = function(x){list(DataChannel = x)})
#put into a data frame
reports <- tibble(output_file, params)
## renders with params to all
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html", output_file = x[[1]], params = x[[2]]
)
}
)
## renders single github doc with parameters lifestyle
#rmarkdown::render("/GitHub/ST_558_Project_2/_Rmd/Automation_test.Rmd", output_file = "Lifestyle.md",
#params = list(data_channel_is = "Lifestyle"))
## renders all 6 documents
## creates a list of all 6 desired params from online
data_channel_is <- c("Lifestyle", "Entertainment", "Business", "Social.Media", "Tech", "World")
output_file <- paste0(data_channel_is, ".html")
#create a list for each team with just the team name parameter
params = lapply(data_channel_is, FUN = function(x){list(DataChannel = x)})
#put into a data frame
reports <- tibble(output_file, params)
## renders with params to all
apply(reports, MARGIN=1, FUN = function(x){
rmarkdown::render("./_Rmd/Automation_test.Rmd", output_dir = "./automations_test_html", output_file = x[[1]], params = x[[2]]
)
}
)
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
#All trained data sets are in another .Rmd file called Create_dataframes_use_later. These can be copy and pasted when they are necessary
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
lifestyle <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
lifestyle <- lifestyle %>%
filter(Lifestyle == 1)
#Drop the data_channel_is column
lifestyle <- lifestyle[ , -c(12)]
lifestyle <- lifestyle[ , c(53, 1:52)]
#Split the data into training and test
set.seed(5432)
# Split the data into a training and test set (70/30 split)
# indices
train <- sample(1:nrow(lifestyle), size = nrow(lifestyle)*.70)
test <- setdiff(1:nrow(lifestyle), train)
# trainiing and testing subsets
lifestyle_train <- lifestyle[train, ]
lifestyle_test <- lifestyle[test, ]
## linear regression model using all predictors
linear_model_1 <- train( shares ~ .,
data = lifestyle_train,
method = "lm",
preProcess = c("center", "scale"),
trControl = trainControl(method = "cv",
number = 5))
## prediction of test with model
linear_model_1_pred <- predict(linear_model_1, newdata = dplyr::select(lifestyle_test, -shares))
## storing error of model on test set
linear_1_RMSE<- postResample(linear_model_1_pred, obs = lifestyle_test$shares)
## Delete ## i think this looks good! smart things to cut out, i will try to improve mine. ##
#Removed rate.Nonstop because it was only 1 and removed the days of the week.
linear_model_2 <- train( shares ~. - Rate.Nonstop - Mon
- Tues - Wed - Thurs - Fri - Sat
- Sun - Weekend,
data = lifestyle_train,
method = "lm",
preProcess = c("center",
"scale"),
trControl = trainControl(
method= "cv",
number = 5))
## prediction of test with model
linear_model_2_pred <- predict(linear_model_2, newdata = dplyr::select(lifestyle_test, -shares))
## storing error of model on test set
linear_2_RMSE<- postResample(linear_model_2_pred, obs = lifestyle_test$shares)
#Cross validation not needed on random forest
set.seed(10210526)
#Removed rate.nonstop because they were all 1. Removed Mon-Sat and Weekend because they were binary/categorical
lifestyle_train2 <- lifestyle_train %>%
select(-c('Rate.Nonstop',
'Mon', 'Tues',
'Wed', 'Thurs',
'Fri', 'Sat',
'Sun',
'Weekend'))
rfFit <- randomForest(shares ~ ., data = lifestyle_train2,
mtry = ncol(lifestyle_train2)/3,
ntree = 200, importance = TRUE)
rfFit
e <- as.data.frame(rfFit$importance)
e
e <- e %>%
select(c('%IncMSE'))
max(e)
varImpPlot(rfFit,scale=TRUE, var = 20)
rfPred <- predict(rfFit, newdata =
dplyr::select(lifestyle_test, -shares))
rfRMSE <- sqrt(mean((rfPred-lifestyle_test$shares)^2))
rfRMSE
#Please look over this. What do you think? There are far too many variables, but I am not sure which ones to get rid of that I haven't already.
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20)*10 ,
shrinkage = 0.1,
n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ ., data = lifestyle_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## plot to visualize parameters
plot(gbm_tree_cv)
## creates boosted tree model with tuning parameters n.trees, shrinkage, interaction.depth from CV
boosted_tree_model <- gbm(shares ~ ., data = lifestyle_train,
distribution = "gaussian",
n.trees = 16 ,
shrinkage = 0.1 ,
interaction.depth = 7 )
## test set prediction
boosted_tree_model_pred <- predict(boosted_tree_model, newdata = dplyr::select(lifestyle_test, -shares), n.trees = 7)
## stores results
boosted_tree_RMSE <- postResample(boosted_tree_model_pred, obs = lifestyle_test$shares)
## creates a data frame of the four models RMSE on the
models_RMSE <- data.frame(linear_1_RMSE=linear_1_RMSE[1],
linear_2_RMSE=linear_2_RMSE[1],
rfRMSE=rfRMSE[1],
boosted_tree_RMSE = boosted_tree_RMSE[1] )
## gets the name of the column with the smallest rmse
smallest_RMSE<-colnames(models_RMSE)[apply(models_RMSE,1,which.min)]
## declares the model with smallest RSME the winner
paste0(" For ",
## parameter will be lifestyle for this one I think
#parameter,
smallest_RMSE, " is the winner")
models_RMSE
as_tibble(online)
names(online)
