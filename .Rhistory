rfFit
e <- as.data.frame(rfFit$importance)
e
e <- e %>%
select(c('%IncMSE'))
max(e)
varImpPlot(rfFit,scale=TRUE, var = 20)
rfPred <- predict(rfFit, newdata =
dplyr::select(lifestyle_test, -shares))
rfRMSE <- sqrt(mean((rfPred-lifestyle_test$shares)^2))
rfRMSE
#Please look over this. What do you think? There are far too many variables, but I am not sure which ones to get rid of that I haven't already.
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20)*10 ,
shrinkage = 0.1,
n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ ., data = lifestyle_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## plot to visualize parameters
plot(gbm_tree_cv)
## creates boosted tree model with tuning parameters n.trees, shrinkage, interaction.depth from CV
boosted_tree_model <- gbm(shares ~ ., data = lifestyle_train,
distribution = "gaussian",
n.trees = 16 ,
shrinkage = 0.1 ,
interaction.depth = 7 )
## test set prediction
boosted_tree_model_pred <- predict(boosted_tree_model, newdata = dplyr::select(lifestyle_test, -shares), n.trees = 7)
## stores results
boosted_tree_RMSE <- postResample(boosted_tree_model_pred, obs = lifestyle_test$shares)
## creates a data frame of the four models RMSE on the
models_RMSE <- data.frame(linear_1_RMSE=linear_1_RMSE[1],
linear_2_RMSE=linear_2_RMSE[1],
rfRMSE=rfRMSE[1],
boosted_tree_RMSE = boosted_tree_RMSE[1] )
## gets the name of the column with the smallest rmse
smallest_RMSE<-colnames(models_RMSE)[apply(models_RMSE,1,which.min)]
## declares the model with smallest RSME the winner
paste0(" For ",
## parameter will be lifestyle for this one I think
#parameter,
smallest_RMSE, " is the winner")
models_RMSE
as_tibble(online)
names(online)
library(tidyverse)
library(knitr)
library(GGally)
library(corrplot)
library(qwraps2)
library(vtable)
library(psych)
library(ggplot2)
library(cowplot)
library(caret)
library(gbm)
library(randomForest)
library(tree)
library(class)
library(bst)
library(reshape)
library(reshape2)
library(corrr)
install.packages("corrr")
library(tidyverse)
library(knitr)
library(GGally)
library(corrplot)
library(qwraps2)
library(vtable)
library(psych)
library(ggplot2)
library(cowplot)
library(caret)
library(gbm)
library(randomForest)
library(tree)
library(class)
library(bst)
library(reshape)
library(reshape2)
library(corrr)
library(ggcorrplot)
install.packages("ggcorrplot")
library(tidyverse)
library(knitr)
library(GGally)
library(corrplot)
library(qwraps2)
library(vtable)
library(psych)
library(ggplot2)
library(cowplot)
library(caret)
library(gbm)
library(randomForest)
library(tree)
library(class)
library(bst)
library(reshape)
library(reshape2)
library(corrr)
library(ggcorrplot)
library(FactoMineR)
install.packages("FactoMineR")
setwd("C:/Documents/Github/ST_558_Project_2")
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
online
online[,12:17]
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
online[,12:17]
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
library(tidyverse)
library(knitr)
library(GGally)
library(corrplot)
library(qwraps2)
library(vtable)
library(psych)
library(ggplot2)
library(cowplot)
library(caret)
library(gbm)
library(randomForest)
library(tree)
library(class)
library(bst)
library(reshape)
library(reshape2)
library(corrr)
library(ggcorrplot)
library(FactoMineR)
library(factoextra)
#setwd("C:/Documents/Github/ST_558_Project_2")
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
#All trained data sets are in another .Rmd file called Create_dataframes_use_later. These can be copy and pasted when they are necessary
## I'm not 100% sure but I think we are supposed to run this same process with the different params set up. so its like just one doc that we knit with the six different params and it goes through and does everything without us needing to copy and paste
online
online[,12:17]
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
online %>% filter( !!rlang::sym(params$DataChannel) == 1)
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
lifestyle <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
lifestyle <- lifestyle %>%
filter(Lifestyle == 1)
#Drop the data_channel_is column
lifestyle <- lifestyle[ , -c(12)]
lifestyle <- lifestyle[ , c(53, 1:52)]
data_channel
data_channel[,12:17]
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
data_channel[,12:17]
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
params
params$DataChannel
getwd()
setwd("./Github/ST_558_Project_2")
setwd("./ST_558_Project_2")
getwd()
## just changed this so it would work on my machine feel free to change it back
#setwd("C:/Documents/Github/ST_558_Project_2")
setwd("C:/Users/Demetri/Documents/NCSU_masters/ST558/Repos/GitHub/ST_558_Project_2")
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
#All trained data sets are in another .Rmd file called Create_dataframes_use_later. These can be copy and pasted when they are necessary
## I'm not 100% sure but I think we are supposed to run this same process with the different params set up. so its like just one doc that we knit with the six different params and it goes through and does everything without us needing to copy and paste
params$DataChannel
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
## Drop the data_channel_is columns
data_channel <- data_channel[ , -c(12:17)]
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
data_channel[,12:17]
params$DataChannel
params:
DataChannel: "Lifestyle"
title: "Project 2"
params$DataChannel
params$DataChannel
params$DataChannel
## just changed this so it would knit on my machine feel free to change it back if i forget
#setwd("C:/Documents/Github/ST_558_Project_2")
setwd("C:/Users/Demetri/Documents/NCSU_masters/ST558/Repos/GitHub/ST_558_Project_2")
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
#All trained data sets are in another .Rmd file called Create_dataframes_use_later. These can be copy and pasted when they are necessary
## I'm not 100% sure but I think we are supposed to run this same process with the different params set up. so its like just one doc that we knit with the six different params and it goes through and does everything without us needing to copy and paste
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
params$DataChannel
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
## Drop the data_channel_is columns
data_channel <- data_channel[ , -c(12:17)]
## reorder to put shares first
data_channel <- data_channel[ , c(53, 1:52)]
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
## Drop the data_channel_is columns
data_channel <- data_channel[ , -c(12:17)]
## reorder to put shares first
data_channel <- data_channel[ , c(53, 1:52)]
rm(online)
rm(data_channel)
## just changed this so it would knit on my machine feel free to change it back if i forget
#setwd("C:/Documents/Github/ST_558_Project_2")
setwd("C:/Users/Demetri/Documents/NCSU_masters/ST558/Repos/GitHub/ST_558_Project_2")
online <- read.csv('OnlineNewsPopularity.csv')
colnames(online) <- c('url', 'days', 'n.Title', 'n.Content', 'Rate.Unique',
'Rate.Nonstop', 'Rate.Unique.Nonstop', 'n.Links',
'n.Other', 'n.Images', 'n.Videos',
'Avg.Words', 'n.Key', 'Lifestyle', 'Entertainment',
'Business', 'Social.Media', 'Tech', 'World', 'Min.Worst.Key',
'Max.Worst.Key', 'Avg.Worst.Key', 'Min.Best.Key',
'Max.Best.Key', 'Avg.Best.Key', 'Avg.Min.Key', 'Avg.Max.Key',
'Avg.Avg.Key', 'Min.Ref', 'Max.Ref', 'Avg.Ref', 'Mon',
'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'Weekend',
'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',
'Global.Subj', 'Global.Pol', 'Global.Pos.Rate',
'Global.Neg.Rate', 'Rate.Pos', 'Rate.Neg', 'Avg.Pos.Pol',
'Min.Pos.Pol', 'Max.Pos.Pol', 'Avg.Neg.Pol', 'Min.Neg.Pol',
'Max.Neg.Pol', 'Title.Subj', 'Title.Pol', 'Abs.Subj',
'Abs.Pol', 'shares')
#Dropped url and timedelta because they are non-predictive.
online <- online[ , c(3:61)]
#All trained data sets are in another .Rmd file called Create_dataframes_use_later. These can be copy and pasted when they are necessary
## I'm not 100% sure but I think we are supposed to run this same process with the different params set up. so its like just one doc that we knit with the six different params and it goes through and does everything without us needing to copy and paste
## filters rows based on when parameter is 1
data_channel <-  online %>% filter( !!rlang::sym(params$DataChannel) == 1)
## Drop the data_channel_is columns
data_channel <- data_channel[ , -c(12:17)]
## reorder to put shares first
data_channel <- data_channel[ , c(53, 1:52)]
set.seed(5432)
# Split the data into a training and test set (70/30 split)
# indices
train <- sample(1:nrow(data_channel), size = nrow(data_channel)*.70)
test <- setdiff(1:nrow(data_channel), train)
# training and testing subsets
data_channel_train <- data_channel[train, ]
data_channel_test <- data_channel[test, ]
## linear regression model using all predictors
linear_model_1 <- train( shares ~ .,
data = data_channel_train,
method = "lm",
preProcess = c("center", "scale"),
trControl = trainControl(method = "cv",
number = 5))
## prediction of test with model
linear_model_1_pred <- predict(linear_model_1, newdata = dplyr::select(data_channel_test, -shares))
## storing error of model on test set
linear_1_RMSE<- postResample(linear_model_1_pred, obs = data_channel_test$shares)
## Delete ## i think this looks good! smart things to cut out, i will try to improve mine. ##
#Removed rate.Nonstop because it was only 1 and removed the days of the week.
linear_model_2 <- train( shares ~. - Rate.Nonstop - Mon
- Tues - Wed - Thurs - Fri - Sat
- Sun - Weekend,
data = lifestyle_train,
method = "lm",
preProcess = c("center",
"scale"),
trControl = trainControl(
method= "cv",
number = 5))
#Create data_channel_is_lifestyle dataset
#Take out all data_Channel_is columns that are not relevant to this data set
lifestyle <- online[ , -c(13:17)]
#Filter out the zeros from the remaining data_channel_is column
lifestyle <- lifestyle %>%
filter(Lifestyle == 1)
#Drop the data_channel_is column
lifestyle <- lifestyle[ , -c(12)]
lifestyle <- lifestyle[ , c(53, 1:52)]
#Split the data into training and test
set.seed(5432)
# Split the data into a training and test set (70/30 split)
# indices
train <- sample(1:nrow(lifestyle), size = nrow(lifestyle)*.70)
test <- setdiff(1:nrow(lifestyle), train)
# trainiing and testing subsets
lifestyle_train <- lifestyle[train, ]
lifestyle_test <- lifestyle[test, ]
## Delete ## i think this looks good! smart things to cut out, i will try to improve mine. ##
#Removed rate.Nonstop because it was only 1 and removed the days of the week.
linear_model_2 <- train( shares ~. - Rate.Nonstop - Mon
- Tues - Wed - Thurs - Fri - Sat
- Sun - Weekend,
data = lifestyle_train,
method = "lm",
preProcess = c("center",
"scale"),
trControl = trainControl(
method= "cv",
number = 5))
## prediction of test with model
linear_model_2_pred <- predict(linear_model_2, newdata = dplyr::select(lifestyle_test, -shares))
## storing error of model on test set
linear_2_RMSE<- postResample(linear_model_2_pred, obs = lifestyle_test$shares)
set.seed(10210526)
rfFit <- train(shares ~ .,
data = lifestyle_train,
method = "rf",
trControl = trainControl(method = "cv",
number = 5),
preProcess = c("center", "scale"),
tuneGrid =
data.frame(mtry = ncol(lifestyle_train)/3))
rfFit_pred <- predict(rfFit, newdata = lifestyle_test)
rfRMSE<- postResample(rfFit_pred, obs =
lifestyle_test$shares)
## Delete## i think it looks good! i will need to rewatch the lecture and try to dig in some more cause im really lost on these ensamble tree based models. i think you chose some good ones to remove.  the only thing is in the project it says "Both models should be chosen using cross-validation" for random forest and boosted tree, so i think the random forest does need cv unless im missing something. Im still trying to figure out what is wrong with my cross validation and a way to take the tuning parameters based on each data_channel_is during the automation process. I think we are close though!
## Delete## I rewatched the lecture for model fitting using the caret package. I made the appropriate modifications. I tried to use the tuneGrid but the code was trying to run for over 5 minutes and it never went through, so I used the suggested mtry for regression from the random forest lecture.
## cross validation on boosted tree method to find optima tuning parameters
## DELETE after ## I'm really confused as to why higher values are not giving better rsme for tuning I'm going to go to office hours 7/3 to try to figure out. will use random parameters for now  ##
## creates grid of possible tuning parameters
gbm_grid <-  expand.grid(interaction.depth = c(1,4,7),
n.trees = c(1:20) ,
shrinkage = 0.1,
n.minobsinnode = c(20, 40))
## sets trainControl method
fit_control <- trainControl(method = "repeatedcv",
number = 5,
repeats= 1)
set.seed(13)
## trains to find optimal tuning parameters except it is giving weird parameters
gbm_tree_cv <- train(shares ~ ., data = data_channel_train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = fit_control,
tuneGrid= gbm_grid,
verbose=FALSE)
## plot to visualize parameters
plot(gbm_tree_cv)
## creates boosted tree model with tuning parameters n.trees, shrinkage, interaction.depth from CV
boosted_tree_model <- gbm(shares ~ ., data = data_channel_train,
distribution = "gaussian",
n.trees = 16 ,
shrinkage = 0.1 ,
interaction.depth = 7 )
## test set prediction
boosted_tree_model_pred <- predict(boosted_tree_model, newdata = dplyr::select(data_channel_test, -shares), n.trees = 7)
## stores results
boosted_tree_RMSE <- postResample(boosted_tree_model_pred, obs = data_channel_test$shares)
## creates a data frame of the four models RMSE on the
models_RMSE <- data.frame(linear_1_RMSE=linear_1_RMSE[1],
linear_2_RMSE=linear_2_RMSE[1],
rfRMSE=rfRMSE[1],
boosted_tree_RMSE =
boosted_tree_RMSE[1] )
## gets the name of the column with the smallest rmse
smallest_RMSE<-colnames(models_RMSE)[apply(models_RMSE,1,which.min)]
## declares the model with smallest RSME the winner
paste0(" For ",
params$DataChannel,
smallest_RMSE, " is the winner")
## creates a data frame of the four models RMSE on the
models_RMSE <- data.frame(linear_1_RMSE=linear_1_RMSE[1],
linear_2_RMSE=linear_2_RMSE[1],
rfRMSE=rfRMSE[1],
boosted_tree_RMSE =
boosted_tree_RMSE[1] )
## gets the name of the column with the smallest rmse
smallest_RMSE<-colnames(models_RMSE)[apply(models_RMSE,1,which.min)]
## declares the model with smallest RSME the winner
paste0(" For ",
params$DataChannel, " ",
smallest_RMSE, " is the winner")
## delete## exploratory to try to figure out which variables to include in models cause weird results. might need to prescreen and pick less variables for modeling  ##
cor(data_channel_train)[1,] %>% sort()
## delete## exploratory to try to figure out which variables to include in models cause weird results. might need to prescreen and pick less variables for modeling  ##
cor(data_channel_train)[1,] %>% sort() %>% as_tibble
## delete## exploratory to try to figure out which variables to include in models cause weird results. might need to prescreen and pick less variables for modeling  ##
cor(data_channel_train)[1,] %>% sort()
shares_correlations <- cor(data_channel_train)[1,] %>% sort()
shares_correlations
shares_correlations[1]
shares_correlations[53]
shares_correlations[52]
shares_correlations[48:52]
shares_correlations[[52]]
g <-ggplot(data_channel_train,  aes(y=shares, x= shares_correlations[[52]]))
g+ geom_point()
data_channel_train[52]
shares_correlations[52]
shares_correlations[52] %>% name()
shares_correlations[52] %>% names()
str(shares_correlations)
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[52]]))
g+ geom_point()
highest_cor
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[highest_cor]))
g+ geom_point()
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point()
highest_cor
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[n.Videos]))
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[n.Videos]]))
g+ geom_point()
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[n.Videos]))
g+ geom_point()
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train$n.Videos))
g+ geom_point()
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]])
g+ geom_point()
## take the name of the highest correlated variable
highest_cor <-shares_correlations[52]  %>% names()
g <-ggplot(data_channel_train,  aes(y=shares, x= data_channel_train[[highest_cor]]))
g+ geom_point()
